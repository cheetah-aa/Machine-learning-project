Methodology
The project followed a standard machine learning pipeline with careful attention to data preparation, analysis, and model evaluation:

1. Data Acquisition
- Loaded a public dataset related to lung cancer from Kaggle.
- Verified data integrity and structure.

2. Data Preprocessing
- Data Cleaning:
  . Checked for null or missing values (none found or handled accordingly).
  . Corrected any inconsistent values (e.g., target labels or column formatting).

- Outlier Detection and Removal:
  . The Interquartile Range (IQR) method was used to detect and remove outliers, especially in the AGE feature.
  . This helped reduce skewness and improve model performance.

- Label Encoding:
  . Converted categorical string labels to numerical values (e.g., YES/NO to 1/0) to make the dataset machine-learning compatible.

3. Exploratory Data Analysis (EDA)
- Boxplots:
  . Used to visualize distributions and detect outliers (e.g., AGE vs. LUNG_CANCER).

- Scatterplots:
  . It could be used to visualize the correlation between features, though not all features were continuous.

- Feature Correlation Matrix:
  . It can be used to identify relationships between variables.

4. Feature Selection
- Retained all relevant features since all attributes in the dataset appeared directly related to the target label (LUNG_CANCER).
- Feature importance was later assessed using the Random Forest model.

5. Model Building
- Trained and compared three machine learning classifiers:
  . Logistic Regression – simple baseline model
  . Support Vector Classifier -
  . Random Forest Classifier – ensemble model selected as final due to superior accuracy and generalization
  . XGBoost Classifier - 

6. Model Evaluation
- Split the dataset into training and testing sets (e.g., 80/20 split).
- Evaluated models using:
  . Accuracy Score
  . Confusion Matrix
  . Classification Report (Precision, Recall, F1-score)
- XGBoost Classifier performed the best with 97% accuracy.

7. Hyperparameter Tuning
- Basic tuning applied to Random Forest:
  . n_estimators: 100
  . max_depth: experimented manually for best performance
  . random_state: 42 for reproducibility

